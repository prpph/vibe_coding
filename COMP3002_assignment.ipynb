{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - Applications of Big Data (COMP3002)\n",
    "\n",
    "__Due: EOD Monday, 16th june 2025 AEDT 23:59__\n",
    "\n",
    "\n",
    "__Centre for Research in Mathematics And Data Science__\n",
    "\n",
    "__School of Computer, Data and Mathematical Sciences__\n",
    "\n",
    "\n",
    "## Description\n",
    "For this assignment, you will need to create a complete program to perform sentiment classification for movie reviews from feature extraction to classification. For a given review, your program should be able to predict whether it is positive i.e. like the movie, or negative, i.e. dislike the movie. \n",
    "\n",
    "## About the data\n",
    "You will use a large movie review dataset containing a set of 25,000 movie reviews for training, and 25,000 for testing. You can download the data from the vUWS under the assignments folder named aclImdb.zip. You can also visit the following website for more information about the dataset at http://ai.stanford.edu/~amaas/data/sentiment/ or download data directly from there. \n",
    "\n",
    "Unzip the data to your local directory. Enter the aclImdb/ directory created by the zip file (~500MB), you will find the following three items among others\n",
    "\n",
    "- train/: feature files and raw text files for the training set\n",
    "- test/: feature files and raw text files for the testing set\n",
    "- README: the readme file for more information on the dataset\n",
    "\n",
    "Read the README file carefully about the descriptions on the text files that contain the reviews and their naming convention. The directories we concern here are \n",
    "\n",
    "- ./aclImdb/train/pos: raw text files of positive reviews in the training set\n",
    "- ./aclImdb/train/neg: raw text files of negative reviews in the training set\n",
    "- ./aclImdb/test/pos: raw text files of positive reviews in the test set\n",
    "- ./aclImdb/test/neg: raw text files of negative reviews in the test set\n",
    "\n",
    "A full version of this data set is available at hdfs://hadoop.cdms.westernsydney.edu.au:9000/users/bigdata/Hadoop/imdb/fullversion. A tiny cut down version with much less number of files (20 each for training and 10 each for test) is also available at hdfs://hadoop.cdms.westernsydney.edu.au:9000/users/bigdata/Hadoop/imdb/tinyversion. The tiny version is for experimenting purpose. \n",
    "\n",
    "## Task 1. Feature extraction (15 points)\n",
    "Use the map reduce model to convert all text data into matrices. Convert _ratings_ to vectors. These will be used for classification in Task 2. Use TF-IDF to vectorise the text files. See previous practical classes and lectures materials for TF-IDF. One step further though is to represent each text file (review) as a very long and sparse vector as the following. Assume `wordslist` is the final list of distinct words contained in all reviews and its length is $D$. Then each review will be a vector of length $D$, with each position associated with a word in `wordlist` and the value being either 0, if the corresponding word is absent in the review, or the word’s TF-IDF. For example, if `wordlist = [‘word1’, ‘word2’, ‘word3’, ‘word4’]` and review 1 contains `word1` and `word4`, then the vector representation of review 1 is [0.1, 0, 0, 0.4] assuming TF-IDF of `word1` and `word4` in review 1 is 0.1 and 0.4 respectively. Note that TF is calculated from one single document while IDF is obtained from all documents in the collection. \n",
    "\n",
    "### Requirements: \n",
    "\n",
    "1. Map reduce model is a must. Implement it using Hadoop streaming. All data are available on SCDMS HDFS. The recommendation is to work on the tiny version of the data to make the code work. You may try your code on the full version. However, the application to full version is not required. \n",
    "2. Generate two matrices: `training_data`, `test_data`, and two vectors, `training_targets`, `test_targets`. `training_data` should have $N$ rows and $D$ columns with each row corresponding to each review in the training set, where $N$ is the totally number of reviews in training set and $D$ is the total number of words. $N$ and $D$ vary depending on which version of the data you use. `training_targets` should have $N$ elements each of which is the rating of the review is for. `test_data` and `test_targets` are similar defined. \n",
    "\n",
    "Note:\n",
    "\n",
    "<!--1.\tIf feature extraction is too difficult for you, you can use pre-computed bag of words features included in this data set. Refer to the Appendix and README file for details. However, if pre-computed features are used, __a 60% penalty__ will incur for this task, i.e. the maximum marks you can get from this task is 6 if you do so. -->\n",
    "- Ratings scores extraction can be purely python. \n",
    "- Using map reduce model to extract TF-IDF is mandatory. If not used, a __50% penalty__ for this task will incur. There is no constraint on how to form the training and test matrices and vectors. There are many versions of TF-IDF. There is no preference for which version to use.\n",
    "- You can use data frame (using `pandas` package) instead of matrices and vectors to store training and test data and targets. \n",
    "\n",
    "### Marking scheme for task 1:\n",
    "\n",
    "<!--- Text file reading (1pt): read the text files for TF-IDF extraction. -->\n",
    "- Rating scores extraction (3pts): parse the name of text files to extract ratings.\n",
    "- TF-IDF extraction (10pts):  use map reduce model to extract TF-IDF for each text file.  \n",
    "- Forming matrices and target vectors (or data frames) (2pts): collect TF-IDFs to form training and test data for task 2. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: submission \n",
    "Your work goes from here. Add blocks when neceesay. Add inline comments in python code or in markdown blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes my first mapreducer, mapredcue1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your python code for mapreduce1\n",
    "# Assuming you use separate python source files for mapper and reducer. \n",
    "# save as hadoopmapper1.py\n",
    "\n",
    "\n",
    "# save as hadoopreducer1.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following script in hadoop with the above python source files saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \\\n",
    "  -mapper hadoopmapper1.py \\\n",
    "  -reducer hadoopreducer1.py \\\n",
    "  -input /users/bigdata/imdb/tinyversion \\\n",
    "  -output /hdfs/path/to/outputdirectory \\\n",
    "  -file local/path/to/hadoopmapper1.py \\\n",
    "  -file local/path/to/hadoopreducer1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes my second mapreducer, mapredcue2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your python code for mapreduce1\n",
    "# Assuming you use a single python source file for mapper and reducer. \n",
    "# save as hadoopmapreducer2.py\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following script in hadoop with the above python source file saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \\\n",
    "  -mapper 'python hadoopmapreducer2.py map' \\\n",
    "  -reducer 'python hadoopmapreducer2.py reduce' \\\n",
    "  -input /users/bigdata/imdb/tinyversion \\\n",
    "  -output /hdfs/path/to/outputdirectory \\\n",
    "  -file local/path/to/hadoopmapreducer2.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px;border-width:0;color:gray;background-color:green\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Classification (15 points)\n",
    "Construct a classification model for review sentiment prediction, meaning that given a customer review (taken from test set) about a movie, your program should be able to predict whether it is positive or negative. There is no limitation on how many classifiers and what specific model you should use. You can simply pick one that works for you for this task, either from those covered in lectures and practical classs or any other classifiers from any python packages. A good starting point is the `scikit-learn` (i.e. `sklearn`) package. \n",
    "A few things you need to address in your python program are listed as requirements below. \n",
    "\n",
    "### Requirements: \n",
    "\n",
    "1.\tData pre-processing. In task 1, you have extracted the ratings vectors for training and test. They are raw ratings. As we are interested in sentiment prediction, i.e. to predict either the review is positive or negative. You need to convert all ratings>5 as positive class and ratings<=5 as negative class. Choose a coding scheme, e.g. 1 for positive, 0 for negative. \n",
    "2.\tNormalisation. Apply at least one normalisation scheme and compare the performance of the classifier(s) with and without normalisation. \n",
    "3.\tTraining and model selection. Use cross validation to select the best parameters for your classifier. There may be many parameters to tune in some classifiers such as random forest classifier (RFC). You can focus on the most important one(s) such as `max_depth` and `n_estimators` in RFC. Refer to `scikit-learn` package documentation for details. \n",
    "Hint: you can start with a small subset of training set to test a few parameters to get a feel of what range the parameters should be that make the model perform well in terms of prediction accuracy. Then turn on large scale cross validation on the whole training set.  \n",
    "4.\tTest on test data. After model selection, apply the best model, i.e. model with the parameters that produces the best cross validation scores, to test data and make prediction for each review and record prediction accuracy (ACC). \n",
    "\n",
    "Note: \n",
    "\n",
    "1. Always train your classifier(s) ONLY on training data including cross validation. After model selection, apply the best model on test data to evaluate the performance. \n",
    "2. Good performance, i.e. higher ACC on test data, is not essential for this task. However, if your classifier has ACC low than 60%, it usually means that there are some mistakes somewhere in your code. So try to score as high ACC as possible. \n",
    "3.\tYou are encouraged to try many classifiers. If the coding is right, this should not be too difficult. Remember model selection when you try different classifiers!\n",
    "\n",
    "### Marking scheme for task 2:\n",
    "\n",
    "- Data pre-processing (1pts): convert ratings to positive and negative coding scheme. \n",
    "- Normalisation and comparison (3pts): apply normalisation and compare performance difference with and without it.\n",
    "- Training on training data (3pts): training performed on training data.\n",
    "- Cross validation (6pts): apply cross validation on training data. \n",
    "- Testing on test data (2pts): best model applied to test data and ACC produced.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: submission \n",
    "Your work goes from here. Add blocks when neceesay. Add inline comments in python code or in markdown blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes my first python script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your python code for Task 2: data preprocessing\n",
    "# Your code goes from here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px;border-width:0;color:gray;background-color:blue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Task (10 points)\n",
    "This is a bonus task. It is not essential but if you could complete it as required you will receive 10 extra points towards your final results of this unit. The task is similar to the _Task 5_ in prac 8. \n",
    "\n",
    "Compute the correlation between features and response. Use the TF-IDF as features and review scores as response. Consider only training set, i.e. on `training_data`. Here is the details. Let $\\mathbf x_i$ be the $i$-th TF-IDF _column_ vector you extracted for the $i$-th review, and $y_i$ its corresponding review score. To compute the coorelation, we need $\\tilde{\\mathbf x}_i$ and $\\tilde{y}_i$, normalised version of $\\mathbf x_i$ and $y_i$ as the following. \n",
    "$$\n",
    "\\tilde{\\mathbf x}_i = \\frac{\\hat{\\mathbf x}_i}{\\|\\hat{\\mathbf x}_i\\|} \n",
    "$$\n",
    "where $\\hat{\\mathbf x}_i = \\mathbf x_i - \\mathbf m$, $\\mathbf m$ is the mean of all features, i.e. $ \\mathbf m = \\frac{\\sum_{i=1}^N \\mathbf x_i}N$, and $\\|\\hat{\\mathbf x}_i\\|$ is the so-called $\\ell_2$ norm of $\\|\\hat{\\mathbf x}_i\\|$ which is defined as \n",
    "$$\\|\\hat{\\mathbf x}_i\\| = \\sqrt{\\sum_{j=1}^Dx_{i_j}^2}$$\n",
    "i.e. the square root of the sum of squares of all the elements in vector $\\hat{\\mathbf x}_i$. $\\tilde{y}_i$ is similar \n",
    "$$ \\tilde{y}_i = \\frac{y_i}{\\|\\mathbf y\\|}$$\n",
    "where $\\mathbf y=[y_1,\\ldots,y_N]$ is the vector of all review scores. Then the correlation $\\mathbf r$ is  \n",
    "$$\n",
    "\\mathbf r = \\sum_{i=1}^N\\tilde{y}_i\\tilde{\\mathbf x}_i.\n",
    "$$\n",
    "$\\mathbf r$ will be a vector of length $D$. \n",
    "\n",
    "### Requirements: \n",
    "\n",
    "1. Use map reduce computing model for this task is mandatory. Direct computing the correlation from the matrices obtained from Task 1, i.e. `training_data` is _not_ acceptable. \n",
    "\n",
    "2. Python code and Hadoop streaming commands must be supplied for this taks. If multiple map reduce steps are used, a step-by-step guidance must be provided as well. \n",
    "\n",
    "\n",
    "_Hint: you may consider several map reduce to compute mean, $\\ell_2$ norm, multiplication and etc._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus task : submission \n",
    "Your work goes from here. Add blocks when neceesay. Add inline comments in python code or in markdown blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes my first mapreducer, task3mapredcue1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your python code for mapreduce1\n",
    "# Assuming you use separate python source files for mapper and reducer. \n",
    "# save as task3hadoopmapper1.py\n",
    "\n",
    "\n",
    "# save as task3hadoopreducer1.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following script in hadoop with the above python source files saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \\\n",
    "  -mapper task3hadoopmapper1.py \\\n",
    "  -reducer task3hadoopreducer1.py \\\n",
    "  -input /users/bigdata/imdb/tinyversion \\\n",
    "  -output /hdfs/path/to/outputdirectory \\\n",
    "  -file local/path/to/task3hadoopmapper1.py \\\n",
    "  -file local/path/to/task3hadoopreducer1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes my second mapreducer, task3mapredcue2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your python code for task3mapreduce1\n",
    "# Assuming you use a single python source file for mapper and reducer. \n",
    "# save as task3hadoopmapreducer2.py\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following script in hadoop with the above python source file saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \\\n",
    "  -mapper 'python task3hadoopmapreducer2.py map' \\\n",
    "  -reducer 'python task3hadoopmapreducer2.py reduce' \\\n",
    "  -input /users/bigdata/imdb/tinyversion \\\n",
    "  -output /hdfs/path/to/outputdirectory \\\n",
    "  -file local/path/to/task3hadoopmapreducer2.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:4px;border-width:0;color:red;background-color:red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Marking Criteria for All Tasks\n",
    "\n",
    "Your program will be marked against both functional and operational requirements. Functional requirements accounts for 80% of the mark, which measure how well your program achieves the expected functionalities and are further broken down into the items listed in marking schemes in those tasks. \n",
    "\n",
    "In addition to function requirements, your program should also meet the operational and style requirements, which can be broken down into the following. \n",
    "\n",
    "- Readability (5%): Comments should be included in your program to explain the main idea of your design; use meaningful variable and function names; do not declare variables that are not used in the program \n",
    "- Modularity (10%): Your program should make use of functions or classes wherever possible to achieve modular design and maximise reusability. \n",
    "- Useability (5%): Your program should be easy to use by the user. These include displaying messages for user interaction, performing adequate input validation, and allowing the users to choose the locations of the data file for model training. \n",
    "\n",
    "## Submission\n",
    "Your python code solution including Hadoop streaming commands if any, documentation such as how to use the functions must be written in _this jupyter notebook_ with clear indication which is for which. Rename it to `COMP3002_assignment_yourstudentid.ipynb` and work on it. Add code and markdown blocks as you like. Submit your complete notebook through vUWS before deadline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
